{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "tokenizer_name = \"reshinthadith/codegen_350M_list_manip_5_len\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')  # Using BERT tokenizer as an example\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "def find_overlapping_tokens(text, char_range):\n",
    "\n",
    "    # Tokenize the text\n",
    "    encodings = tokenizer(text, return_offsets_mapping=True, truncation=True, max_length=512)\n",
    "\n",
    "    # Get the list of tokens and their corresponding start and end positions in the original text\n",
    "    offsets = encodings.offset_mapping\n",
    "\n",
    "    # Initialize the list to store the token indices\n",
    "    token_indices = []\n",
    "\n",
    "    # Find the tokens that overlap with the given character range\n",
    "    for token_idx, (token_start, token_end) in enumerate(offsets):\n",
    "        if char_range[0] < token_end and char_range[1] > token_start:  # Check for overlap\n",
    "            token_indices.append(token_idx)  # Token indices are 0-indexed\n",
    "\n",
    "    return token_indices\n",
    "\n",
    "# Testing the function\n",
    "text = \"Hello World! How are you?\"\n",
    "char_range = (0, 11)  # Character range corresponding to \"Hello World\"\n",
    "print(find_overlapping_tokens(text, char_range))  # Outputs: [0, 1, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 14)]\n",
      "[(5, 6), (13, 14), (18, 19), (27, 28), (36, 37)]\n",
      "[3]\n",
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "text = \"sub_n(reverse(take(sort_des(sort_asc([0, -5, -5, 5, 4, 0])),24)),-3)\"\n",
    "# find character range indices for search query\n",
    "search = \"reverse(\"\n",
    "\n",
    "def get_matching_ranges(text, search):\n",
    "    all_match_indices = []\n",
    "    start = 0\n",
    "    while True:\n",
    "        match_index = text.find(search, start)\n",
    "        if match_index == -1:\n",
    "            break\n",
    "        all_match_indices.append((match_index, match_index + len(search)))\n",
    "        start = match_index + 1\n",
    "    return all_match_indices\n",
    "\n",
    "all_match_indices = get_matching_ranges(text, search)\n",
    "print(all_match_indices)\n",
    "\n",
    "all_match_indices = get_matching_ranges(text, \"(\")\n",
    "print(all_match_indices)\n",
    "\n",
    "print(find_overlapping_tokens(text, all_match_indices[0]))\n",
    "\n",
    "print(find_overlapping_tokens(text, get_matching_ranges(text, \"sub_n(\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sub', '_', 'n', '(', 'reverse', '(', 'take', '(', 'sort', '_', 'des', '(', 'sort', '_', 'asc', '([', '0', ',', 'Ġ-', '5', ',', 'Ġ-', '5', ',', 'Ġ5', ',', 'Ġ4', ',', 'Ġ0', '])', '),', '24', ')),', '-', '3', ')']\n"
     ]
    }
   ],
   "source": [
    "# print tokenized form of text as a list of tokens each converted to token\n",
    "print(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "def reward_substring_matches(text: str, searches: List[str], max_reward: float) -> List[float]:\n",
    "    \"\"\"\n",
    "    For each search string, find all matching ranges then find all overlapping tokens. Give max_reward for each of the overlapping tokens.\n",
    "    Return a list of rewards for each token in the text. Non-overlapping tokens get 0 reward.\n",
    "    \"\"\"\n",
    "    all_match_indices = []\n",
    "    for search in searches:\n",
    "        all_match_indices += get_matching_ranges(text, search)\n",
    "    all_token_indices = []\n",
    "    for match_index in all_match_indices:\n",
    "        all_token_indices += find_overlapping_tokens(text, match_index)\n",
    "    rewards = [0.0] * len(tokenizer.tokenize(text))\n",
    "    for token_index in all_token_indices:\n",
    "        rewards[token_index] = max_reward\n",
    "    return rewards\n",
    "\n",
    "print(reward_substring_matches(text, [\"reverse(\"], 1.0))\n",
    "print(reward_substring_matches(text, [\"sub_n(\"], 1.0))\n",
    "print(reward_substring_matches(text, [\"reverse(\", \"sub_n(\"], 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
